{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('german_credit_data.csv')\n",
    "\n",
    "#columns to drop\n",
    "df = df.drop(['Number'], axis=1)\n",
    "\n",
    "df.sample(frac=1)\n",
    "\n",
    "index = []\n",
    "count = 0\n",
    "for column in df:\n",
    "    df = df.dropna(subset=[column])\n",
    "\n",
    "\n",
    "\n",
    "# In[1382]:\n",
    "\n",
    "\n",
    "#gets all columns which are not ints and integer encodes them\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "for column in obj_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    df[column] = le.transform(df[column])\n",
    "\n",
    "\n",
    "# In[1383]:\n",
    "\n",
    "\n",
    "#normalize all points between [0,1]\n",
    "x = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset only 1100\n",
    "#create 500/500 split between labelled on nonlablled array, 1000 semi-sup data set, and 100 validation dataset\n",
    "train, test = np.split(df.sample(frac=1), [int(.8*len(df))])\n",
    "train = train.values.tolist()\n",
    "test = test.values.tolist()\n",
    "\n",
    "df_unsupervised = []\n",
    "\n",
    "label_nolabels = {}\n",
    "for point in train:\n",
    "    #unlablled 1000 points data\n",
    "    df_unsupervised.append(point[:-1])\n",
    "    label_nolabels[tuple(point[:-1])]= point[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans2 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans3 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans4 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans5 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans6 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans7 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans8 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans9 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans10 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans11 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans12 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans13 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans14 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans15 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans16 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans17 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans18 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans19 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans20 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans21 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans22 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans23 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans24 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans25 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans26 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans27 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans28 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans29 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans30 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans31 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans32 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans33 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans34 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans35 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans36 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans37 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans38 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans39 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans40 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans41 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans42 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans43 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans44 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans45 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans46 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans47 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans48 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans49 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "kmeans50 = KMeans(n_clusters=2, n_init=10).fit(np.asarray(df_unsupervised))\n",
    "classifiers = [kmeans1, kmeans2, kmeans3, kmeans4, kmeans5, kmeans6, kmeans7, kmeans8, kmeans9, kmeans10, \\\n",
    "               kmeans11, kmeans12, kmeans13, kmeans14, kmeans15, kmeans16, kmeans17, kmeans18, kmeans19, kmeans20, \\\n",
    "               kmeans21, kmeans22, kmeans23, kmeans24, kmeans25, kmeans26, kmeans27, kmeans28, kmeans29, kmeans30, \\\n",
    "               kmeans31, kmeans32, kmeans33, kmeans34, kmeans35, kmeans36, kmeans37, kmeans38, kmeans39, kmeans40, \\\n",
    "               kmeans41, kmeans42, kmeans43, kmeans44, kmeans45, kmeans46, kmeans47, kmeans48, kmeans49, kmeans50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make csv in form of rowNumber, clfNumber, clf prediction on that row\n",
    "answers = []\n",
    "for point in range(len(df_unsupervised)):\n",
    "    for clf in range(len(classifiers)):\n",
    "        answers.append([point, clf, classifiers[clf].predict([df_unsupervised[point]])])\n",
    "\n",
    "count = 0\n",
    "f = open(\"answer_file.csv\", \"w\")\n",
    "f.write('question,worker,answer;\\n')\n",
    "for answer in answers:\n",
    "    count += 1\n",
    "    f.write(str(answer[0]) + ',' + str(answer[1]) + ',' + str(int(answer[2]))+'\\n')\n",
    "f.close()\n",
    "p = open(\"result_file.csv\", \"w\")   \n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run VI BP\n",
    "import subprocess\n",
    "subprocess.call([\"python\", \"run.py\", \"methods/c_EM/method.py\", \"answer_file.csv\", \"result_file.csv\",\"decision-making\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract results, get noisy labels and \n",
    "filepath = \"result_file.csv\"\n",
    "noisy_labels = []\n",
    "with open(filepath) as fp:  \n",
    "    for line in fp:\n",
    "        questionAnswer = line.split(',')\n",
    "        noisy_labels.append(questionAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 417\n"
     ]
    }
   ],
   "source": [
    "#assign noisy label to proper row\n",
    "df_noise_x = [] \n",
    "df_noise_y = []\n",
    "for question in noisy_labels:\n",
    "    if question[0].rstrip() == 'question':\n",
    "        continue\n",
    "    df_noise_x += [df_unsupervised[int(question[0].rstrip())]]\n",
    "    df_noise_y.append(int(question[1].rstrip()))\n",
    "count_vi = 0\n",
    "for el in range(len(df_noise_x)):\n",
    "    if label_nolabels[tuple(df_noise_x[el])][0] != df_noise_y[el]:\n",
    "        count_vi += 1\n",
    "print(count_vi,len(df_noise_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise_y2 = []\n",
    "for el in df_noise_y:\n",
    "    df_noise_y2.append(int(el))\n",
    "\n",
    "df_noise = []\n",
    "for el in range(len(df_noise_x)):\n",
    "    new = df_noise_x[el]\n",
    "    new.append(df_noise_y2[el])\n",
    "    df_noise.append(new)\n",
    "\n",
    "#need to shuffle the data\n",
    "random.shuffle(df_noise)\n",
    "\n",
    "df_noise_x = []\n",
    "df_noise_y = []\n",
    "for row in df_noise:\n",
    "    df_noise_x.append(row[:-1])\n",
    "    df_noise_y.append(row[-1:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=20, random_state=None)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run AdaBoost from Sklearn on noisy data\n",
    "bdt2 = AdaBoostClassifier(DecisionTreeClassifier(),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=20)\n",
    "bdt2.fit(df_noise_x, df_noise_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.6095238095238096\n"
     ]
    }
   ],
   "source": [
    "#Ada boosting on noisy data error rate\n",
    "errors = []\n",
    "count1 = 0\n",
    "for point in test:\n",
    "    est = bdt2.predict([point[:-1]])\n",
    "    true = int(point[-1:][0])\n",
    "    est = int(est[0])\n",
    "    if est == true:\n",
    "        errors.append([point[:-1],0])\n",
    "    else:\n",
    "        count1 += 1\n",
    "        errors.append([point[:-1],1])\n",
    "\n",
    "#error rate, noisy -> baseline \n",
    "print(count1, count1/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
